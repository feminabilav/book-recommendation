# -*- coding: utf-8 -*-
"""Copy of MLTerapan_Proyek_Akhir.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1fsWB8fLf1V0zgNjhs6dKizZiiMJW3Axr

Import dataset menggunakan Kaggle API
"""

!pip install kaggle
!mkdir ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json
!kaggle datasets download -d arashnic/book-recommendation-dataset

!unzip /content/book-recommendation-dataset.zip

# Import library
import pandas as pd
import numpy as np
from zipfile import ZipFile
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from pathlib import Path
import matplotlib.pyplot as plt

"""Setiap file .csv dibaca dan dimasukkan ke dataframe masing-masing"""

books = pd.read_csv('/content/Books.csv')
ratings = pd.read_csv('/content/Ratings.csv')
users = pd.read_csv('/content/Users.csv')

print('Jumlah buku: ', len(books['ISBN'].unique()))
print('Jumlah rating: ', ratings.groupby(['ISBN', 'User-ID']).ngroups)
print('Jumlah user: ', len(users['User-ID'].unique()))

"""# EDA

Dilihat fitur yang dimiliki Books
"""

books.info()

"""Dilihat statistik data yang dimiliki Books"""

books.describe()

"""Dilihat fitur yang dimiliki Ratings"""

ratings.info()

"""Dilihat statistik data yang dimiliki Ratings"""

ratings.describe()

"""Dapat dilihat bahwa rating berada antara 0 sampai 10

Dilihat fitur yang dimiliki Users
"""

users.info()

"""Dilihat statistik data yang dimiliki Users"""

users.describe()

"""Dapat dilihat bahwa max Age adalah 244, sehingga perlu ditangani, juga ada perbedaan count antara User-ID dan Age, ini menandakan bahwa ada missing values

# Data Preperation

Dilakukan merge antara ratings dan books pada kolom ISBN
"""

# Menggabungkan all resto_rate dengan dataframe geo berdasarkan placeID
books_rate = pd.merge(ratings, books[['ISBN','Book-Title', 'Book-Author', 'Year-Of-Publication', 'Publisher']], on='ISBN', how='right')

# Print dataframe all_resto_name
books_rate

"""Kemudian dilakukan juga merge dengan Users pada User-ID"""

# Menggabungkan all resto_rate dengan dataframe geo berdasarkan placeID
all_books = pd.merge(books_rate, users[['User-ID', 'Age']], on='User-ID', how='left')

# Print dataframe all_resto_name
all_books

"""## Outliers dan Missing Values

Dilakukan penanganan outliers pada fitur numerik. Pertama dilakukan visualisasi boxplot terlebih dahulu terhadap data
"""

import seaborn as sns

sns.boxplot(x=all_books['Age'])

"""Terlihat Age memiliki beberapa outliers"""

sns.boxplot(x=all_books['Book-Rating'])

"""Terlihat Book-Rating tidak memiliki outliers"""

print(len(all_books['Year-Of-Publication'].str.contains('')==True))

"""Jika dicek kolom Year-Od-Publication, terlihat bahwa ada beberapa data yang memiliki String sementara Year sendiri seharusnya hanya angka atau int sehingga perlu diperbaiki"""

filter = all_books['Year-Of-Publication'].str.contains('')==True
all_books_filtered = all_books[~filter]
all_books_filtered.shape

"""Setelah di filter terlihat bahwa hanya tersisa 951527 baris data, kemudian kolom ini dijadikan tipe int agar sesuai"""

all_books_filtered['Year-Of-Publication'].astype(int)

"""Dilakukan visualisasi boxplot Year-Of-Publication untuk melihat outliers"""

sns.boxplot(x=all_books_filtered['Year-Of-Publication'])

"""Dapat dilihat bahwa beberapa data merupakan outliers, bahkan ada yang tahun 0

Dilakukan penanganan outliers terhadap Age dan Year-Of-Publication menggunakan IQR seperti berikut
"""

columns = ['Age','Year-Of-Publication']

df = all_books_filtered
for column in columns:
  Q1 = df[column].quantile(0.25)
  Q3 = df[column].quantile(0.75)
  IQR=Q3-Q1
  df=df[~((df[column]<(Q1-1.5*IQR))|(df[column]>(Q3+1.5*IQR)))]

"""Kemudian dicek bahwa outliers sudah terhapus"""

sns.boxplot(x=df['Age'])

sns.boxplot(x=df['Year-Of-Publication'])

"""Dilakukan pengecekan missing values"""

# Mengecek missing value pada dataframe all_resto
df.isnull().sum()

"""Terlihat bahwa ada missing values dengan jumlah terbanyak di Age. Missing values tersebut kemudian di drop"""

df_clean = all_books_filtered.dropna()
df_clean.isnull().sum()

df_clean.shape

"""Terlihat bahwa data yang tersisa adalah 905998 baris

## Collaborative Filtering
"""

df = df_clean

"""Dilakukan encoding pada User-ID dan ISBN ke dalam indeks integer"""

user_ids = df['User-ID'].unique().tolist()
print('list userID: ', user_ids)

user_to_user_encoded = {x: i for i, x in enumerate(user_ids)}
print('encoded userID : ', user_to_user_encoded)

user_encoded_to_user = {i: x for i, x in enumerate(user_ids)}
print('encoded angka ke userID: ', user_encoded_to_user)

book_ids = df['ISBN'].unique().tolist()

book_to_book_encoded = {x: i for i, x in enumerate(book_ids)}

book_encoded_to_book = {i: x for i, x in enumerate(book_ids)}

df.loc[:,'User-ID'] = df['User-ID'].map(user_to_user_encoded)

df.loc[:,'ISBN'] = df['ISBN'].map(book_to_book_encoded)

"""Dilakukan pengecekan jumlah user dan books, juga dilakukan pengbuhan tipe rating menjadi float"""

# Mendapatkan jumlah user
num_users = len(user_to_user_encoded)
print(num_users)

# Mendapatkan jumlah resto
num_book = len(book_encoded_to_book)
print(num_book)

# Mengubah rating menjadi nilai float
df['Book-Rating'] = df['Book-Rating'].values.astype(np.float32)

# Nilai minimum rating
min_rating = min(df['Book-Rating'])

# Nilai maksimal rating
max_rating = max(df['Book-Rating'])

print('Number of User: {}, Number of Books: {}, Min Rating: {}, Max Rating: {}'.format(
    num_users, num_book, min_rating, max_rating
))

"""## Train Test Split

Dilakukan pengacakan dataset untuk menghindari suatu urutan atau bias dari dataset
"""

# Mengacak dataset
df = df.sample(frac=1, random_state=42)
df

"""Dilakukan train test split dengan rasio 80:20"""

# Membuat variabel x untuk mencocokkan data user dan resto menjadi satu value
x = df[['User-ID', 'ISBN']].values

# Membuat variabel y untuk membuat rating dari hasil
y = df['Book-Rating'].apply(lambda x: (x - min_rating) / (max_rating - min_rating)).values

# Membagi menjadi 80% data train dan 20% data validasi
train_indices = int(0.8 * df.shape[0])
x_train, x_val, y_train, y_val = (
    x[:train_indices],
    x[train_indices:],
    y[:train_indices],
    y[train_indices:]
)

print(x, y)

"""# Training

Dibuat class RecommenderNet yang berisi arsitektur model yang akan digunakan, model akan menghitung skor kecocokan antara pengguna dan resto dengan dot product dan teknik embedding
"""

class RecommenderNet(tf.keras.Model):

  # Insialisasi fungsi
  def __init__(self, num_users, num_resto, embedding_size, **kwargs):
    super(RecommenderNet, self).__init__(**kwargs)
    self.num_users = num_users
    self.num_resto = num_resto
    self.embedding_size = embedding_size
    self.user_embedding = layers.Embedding( # layer embedding user
        num_users,
        embedding_size,
        embeddings_initializer = 'he_normal',
        embeddings_regularizer = keras.regularizers.l2(1e-6)
    )
    self.user_bias = layers.Embedding(num_users, 1) # layer embedding user bias
    self.resto_embedding = layers.Embedding( # layer embeddings resto
        num_resto,
        embedding_size,
        embeddings_initializer = 'he_normal',
        embeddings_regularizer = keras.regularizers.l2(1e-6)
    )
    self.resto_bias = layers.Embedding(num_resto, 1) # layer embedding resto bias

  def call(self, inputs):
    user_vector = self.user_embedding(inputs[:,0]) # memanggil layer embedding 1
    user_bias = self.user_bias(inputs[:, 0]) # memanggil layer embedding 2
    resto_vector = self.resto_embedding(inputs[:, 1]) # memanggil layer embedding 3
    resto_bias = self.resto_bias(inputs[:, 1]) # memanggil layer embedding 4

    dot_user_resto = tf.tensordot(user_vector, resto_vector, 2)

    x = dot_user_resto + user_bias + resto_bias

    return tf.nn.sigmoid(x) # activation sigmoid

"""Dilakukan compile terhadap model dengan loss BinaryCrossentropy, optimizer Adam, dan metrik RMSE. Digunakan metrik RMSE untuk mengukur akurasi prediksi rating model"""

model = RecommenderNet(num_users, num_book, 50) # inisialisasi model

# model compile
model.compile(
    loss = tf.keras.losses.BinaryCrossentropy(),
    optimizer = keras.optimizers.Adam(learning_rate=0.001),
    metrics=[tf.keras.metrics.RootMeanSquaredError()]
)

"""Dilakukan training menggunakan batch_size=32 dan epoch=10"""

# Memulai training

history = model.fit(
    x = x_train,
    y = y_train,
    batch_size = 32,
    epochs = 10,
    validation_data = (x_val, y_val)
)

plt.plot(history.history['root_mean_squared_error'])
plt.plot(history.history['val_root_mean_squared_error'])
plt.title('model_metrics')
plt.ylabel('root_mean_squared_error')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()

"""Dapat dilihat bahwa error untuk train data semakin menurun sementara error dari data uji meningkat. Hal ini dapat menandakan bahwa model mengalami overfitting

# Prediction

Dibuat dictionary yang berisi seluruh buku dengan isbn, book_name, dan author
"""

isbn = books['ISBN'].tolist()
author = books['Book-Author'].tolist()
title = books['Book-Title'].tolist()

books_new = pd.DataFrame({
    'isbn': isbn,
    'book_name': title,
    'author': author
})
books_new

"""Kemudian dilakukan prediksi untuk mendapat rekomendasi buku sesuai user"""

books_df = books_new
df = pd.read_csv('/content/Ratings.csv')

# Mengambil sample user
user_id = df['User-ID'].sample(1).iloc[0]
books_read = df[df['User-ID'] == user_id]

books_not_read = books_df[~books_df['isbn'].isin(books_read['ISBN'].values)]['isbn']
books_not_read = list(
    set(books_not_read)
    .intersection(set(book_to_book_encoded.keys()))
)

books_not_read = [[book_to_book_encoded.get(x)] for x in books_not_read]
user_encoder = user_to_user_encoded.get(user_id)
user_resto_array = np.hstack(
    ([[user_encoder]] * len(books_not_read), books_not_read)
)

ratings = model.predict(user_resto_array).flatten()

top_ratings_indices = ratings.argsort()[-10:][::-1]
recommended_books_ids = [
    book_encoded_to_book.get(books_not_read[x][0]) for x in top_ratings_indices
]

print('Showing recommendations for users: {}'.format(user_id))
print('===' * 9)
print('Books with high ratings from user')
print('----' * 8)

top_books_user = (
    books_read.sort_values(
        by = 'Book-Rating',
        ascending=False
    )
    .head(5)
    .ISBN.values
)

books_df_rows = books_df[books_df['isbn'].isin(top_books_user)]
books_df_rows

for row in books_df_rows.itertuples():
    print(row[2],'by', row[3])

print('----' * 8)
print('Top 10 Book recommendation')
print('----' * 8)

recommended_books = books_df[books_df['isbn'].isin(recommended_books_ids)]
for row in recommended_books.itertuples():
    print(row[2],'by', row[3])

"""Dapat dilihat bahwa berhasil diberikan 10 buku rekomendasi bagi user beradasarkan Rating yang telah diberikan User pada buku lain"""